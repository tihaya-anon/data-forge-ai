# DataForge AI - Project Context

> AI-agnostic project context file. Works with any AI coding assistant.

## Project Overview

| Key | Value |
|-----|-------|
| **Name** | DataForge AI |
| **Type** | Portfolio / Demo Project |
| **Purpose** | Job-seeking demonstration of big data + AI/LLM skills |
| **Status** | Demo only, not production code |

### What This Project Demonstrates

1. **LLM Training Data Engineering** - Large-scale data processing pipeline for LLM pre-training
2. **RAG Knowledge Base** - Enterprise intelligent Q&A system with hybrid retrieval

## Tech Stack

| Layer | Technologies |
|-------|-------------|
| Message Queue | Apache Kafka |
| Stream Processing | Apache Flink |
| Batch Processing | Apache Spark |
| Data Lake | Apache Paimon + MinIO |
| Vector Database | Milvus |
| Full-text Search | Elasticsearch |
| Cache | Redis |
| OLAP | Apache Doris |
| Orchestration | Apache Airflow |
| Monitoring | Prometheus + Grafana |
| Diagrams | D2 (Diagrams as Code) |

## Project Structure

```
.
├── Makefile                    # Main entry, includes makefiles/*.mk
├── makefiles/
│   ├── diagrams.mk             # D2 diagram generation
│   ├── docker.mk               # Docker Compose operations
│   └── dev.mk                  # Development utilities
├── docker/
│   ├── compose.base.yml        # Network and volume definitions
│   ├── compose.storage.yml     # Kafka, Milvus, Redis, ES, MinIO
│   ├── compose.compute.yml     # Spark, Flink
│   ├── compose.orchestration.yml # Airflow
│   ├── compose.analytics.yml   # Doris
│   ├── compose.monitoring.yml  # Prometheus, Grafana
│   └── monitoring/             # Prometheus/Grafana configs
├── docs/
│   ├── diagrams/*.d2           # D2 diagram source files
│   ├── images/                 # Generated SVGs (gitignored, CI builds)
│   ├── ARCHITECTURE.md         # Detailed technical architecture
│   └── RESUME_DESCRIPTION.md   # Resume templates & interview prep
├── .ai-context/                # AI assistant context (this folder)
│   ├── CONTEXT.md              # Main context file (this file)
│   └── conventions.yaml        # Structured conventions data
├── .github/workflows/
│   └── generate-diagrams.yml   # Auto-generate diagrams on push
└── README.md                   # Project documentation
```

## Common Commands

```bash
# Show all commands
make help

# Start specific service groups
make docker-storage      # Kafka, Milvus, Redis, ES, MinIO
make docker-compute      # Spark, Flink
make docker-monitoring   # Prometheus, Grafana

# Start everything
make docker-up
make docker-down         # Stop everything

# Generate diagrams locally
make diagrams

# Show service URLs
make urls
```

## Code Conventions

### Makefile

- Use `printf` (not `echo`) for colored output with ANSI codes
- Every target with `## comment` appears in `make help`
- Predefined colors: `$(GREEN)`, `$(YELLOW)`, `$(CYAN)`, `$(RED)`, `$(NC)`
- Modular structure: main `Makefile` includes `makefiles/*.mk`

### Docker Compose

- Each file is **self-contained** (no YAML anchor cross-references between files)
- Network name: `dataforge`
- Container naming convention: `dataforge-<service>`
- **All services must include healthchecks**

### D2 Diagrams

- Theme: `200`
- Layout: `elk`
- Pad: `20`
- **Avoid**: External icon URLs (causes 403 errors)
- **Avoid**: `near: right` (invalid, use `near: top-center` or `near: bottom-center`)
- **Caution**: With markdown blocks `|md ... |`, no special chars after closing `|`

### General

- Chinese comments and labels are acceptable (target audience includes Chinese speakers)
- Focus on architecture demonstration, not implementation details

## Architecture Highlights

### LLM Training Data Pipeline

**Flow**: Data Cleaning → Deduplication (MinHash) → Quality Filtering → PII Removal → Data Mixing

**Key Metrics** (for interview reference):
- Throughput: 50TB+/day
- Deduplication: 10B docs in 4 hours

### RAG Knowledge Base

**Processing**:
- Real-time path: Apache Flink
- Batch path: Apache Spark

**Retrieval Strategy**:
- Vector search (Milvus) + BM25 (Elasticsearch) + RRF fusion + Reranking

**Key Metrics**:
- Sync latency: <5s
- Vector P99: <50ms
- End-to-end: <500ms

## Modification Guidelines

| Task | Action |
|------|--------|
| Add Docker services | Create/modify `docker/compose.*.yml` |
| Add diagrams | Create `.d2` file in `docs/diagrams/`, run `make diagrams` |
| Add Make targets | Add to `makefiles/*.mk` with `## comment` for help |
| Change architecture | Update both diagram AND `docs/ARCHITECTURE.md` |

## Important Notes

1. **SVG files are NOT committed** - Generated by GitHub Actions CI
2. **This is a DEMO project** - Not production-ready code
3. **Languages**: YAML, Markdown, D2, with future Python/Java/Scala for implementation
