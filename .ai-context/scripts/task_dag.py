#!/usr/bin/env python3
"""
ä»»åŠ¡ DAG åˆ†æå·¥å…·

åŠŸèƒ½ï¼š
1. è§£æ tasks.yaml ç”Ÿæˆä¾èµ–å…³ç³»å›¾
2. ç”Ÿæˆ D2 æ ¼å¼çš„å¯è§†åŒ– DAG
3. åˆ†æå¹¶è¡Œåº¦ã€å…³é”®è·¯å¾„
4. ç»™å‡º agent æ•°é‡å»ºè®®
"""

import yaml
import sys
from pathlib import Path
from collections import defaultdict
from typing import Dict, List, Set, Tuple

# =============================================================================
# æ•°æ®åŠ è½½
# =============================================================================

def load_tasks(filepath: str) -> dict:
    """åŠ è½½ä»»åŠ¡é…ç½®æ–‡ä»¶"""
    with open(filepath, 'r', encoding='utf-8') as f:
        return yaml.safe_load(f)


# =============================================================================
# DAG åˆ†æ
# =============================================================================

def build_graph(tasks: List[dict]) -> Tuple[Dict[str, List[str]], Dict[str, List[str]], Dict[str, dict]]:
    """
    æ„å»ºå›¾ç»“æ„
    è¿”å›: (é‚»æ¥è¡¨, åå‘é‚»æ¥è¡¨, ä»»åŠ¡è¯¦æƒ…å­—å…¸)
    """
    graph = defaultdict(list)       # ä»»åŠ¡ -> åç»§ä»»åŠ¡åˆ—è¡¨
    reverse = defaultdict(list)     # ä»»åŠ¡ -> å‰ç½®ä»»åŠ¡åˆ—è¡¨
    details = {}                    # ä»»åŠ¡ -> è¯¦æƒ…
    
    for task in tasks:
        tid = task['ç¼–å·']
        details[tid] = task
        for dep in task.get('ä¾èµ–', []):
            graph[dep].append(tid)
            reverse[tid].append(dep)
    
    return dict(graph), dict(reverse), details


def topological_sort(tasks: List[dict]) -> List[str]:
    """æ‹“æ‰‘æ’åº"""
    graph, reverse, _ = build_graph(tasks)
    all_tasks = {t['ç¼–å·'] for t in tasks}
    
    # è®¡ç®—å…¥åº¦
    in_degree = {t: 0 for t in all_tasks}
    for tid in all_tasks:
        in_degree[tid] = len(reverse.get(tid, []))
    
    # BFS
    queue = [t for t in all_tasks if in_degree[t] == 0]
    result = []
    
    while queue:
        queue.sort()  # ä¿è¯é¡ºåºç¨³å®š
        node = queue.pop(0)
        result.append(node)
        for neighbor in graph.get(node, []):
            in_degree[neighbor] -= 1
            if in_degree[neighbor] == 0:
                queue.append(neighbor)
    
    return result


def compute_levels(tasks: List[dict]) -> Dict[str, int]:
    """
    è®¡ç®—æ¯ä¸ªä»»åŠ¡çš„å±‚çº§ï¼ˆæœ€æ—©å¯å¼€å§‹æ—¶é—´ï¼‰
    å±‚çº§ = max(æ‰€æœ‰å‰ç½®ä»»åŠ¡çš„å±‚çº§) + 1
    """
    graph, reverse, details = build_graph(tasks)
    all_tasks = {t['ç¼–å·'] for t in tasks}
    levels = {}
    
    sorted_tasks = topological_sort(tasks)
    
    for tid in sorted_tasks:
        deps = reverse.get(tid, [])
        if not deps:
            levels[tid] = 0
        else:
            levels[tid] = max(levels[dep] for dep in deps) + 1
    
    return levels


def analyze_parallelism(tasks: List[dict]) -> dict:
    """
    åˆ†æå¹¶è¡Œåº¦
    è¿”å›æ¯ä¸€å±‚çš„ä»»åŠ¡æ•°é‡å’Œç»Ÿè®¡ä¿¡æ¯
    """
    levels = compute_levels(tasks)
    _, _, details = build_graph(tasks)
    
    # æŒ‰å±‚çº§åˆ†ç»„
    level_tasks = defaultdict(list)
    for tid, level in levels.items():
        level_tasks[level].append(tid)
    
    # ç»Ÿè®¡
    parallelism_per_level = []
    total_hours_per_level = []
    
    for level in sorted(level_tasks.keys()):
        tids = level_tasks[level]
        parallelism_per_level.append(len(tids))
        hours = sum(details[tid].get('å·¥æ—¶', 0) or 0 for tid in tids)
        total_hours_per_level.append(hours)
    
    max_parallelism = max(parallelism_per_level)
    max_count = parallelism_per_level.count(max_parallelism)
    avg_parallelism = sum(parallelism_per_level) / len(parallelism_per_level)
    
    # è®¡ç®—åŠ æƒå»ºè®®ï¼ˆè€ƒè™‘æ¯å±‚çš„å·¥æ—¶ï¼‰
    weighted_sum = sum(p * h for p, h in zip(parallelism_per_level, total_hours_per_level))
    total_hours = sum(total_hours_per_level)
    weighted_avg = weighted_sum / total_hours if total_hours > 0 else avg_parallelism
    
    return {
        'levels': dict(level_tasks),
        'parallelism_per_level': parallelism_per_level,
        'hours_per_level': total_hours_per_level,
        'max_parallelism': max_parallelism,
        'max_parallelism_count': max_count,
        'avg_parallelism': avg_parallelism,
        'weighted_avg_parallelism': weighted_avg,
        'total_levels': len(level_tasks),
        'total_tasks': len(tasks),
        'total_hours': total_hours,
    }


def find_critical_path(tasks: List[dict]) -> Tuple[List[str], int]:
    """
    æ‰¾åˆ°å…³é”®è·¯å¾„ï¼ˆæœ€é•¿è·¯å¾„ï¼‰
    è¿”å›: (è·¯å¾„ä¸Šçš„ä»»åŠ¡åˆ—è¡¨, æ€»å·¥æ—¶)
    """
    graph, reverse, details = build_graph(tasks)
    all_tasks = {t['ç¼–å·'] for t in tasks}
    
    # åŠ¨æ€è§„åˆ’è®¡ç®—æœ€é•¿è·¯å¾„
    sorted_tasks = topological_sort(tasks)
    
    dist = {t: details[t].get('å·¥æ—¶', 0) or 0 for t in all_tasks}
    parent = {t: None for t in all_tasks}
    
    for tid in sorted_tasks:
        for neighbor in graph.get(tid, []):
            new_dist = dist[tid] + (details[neighbor].get('å·¥æ—¶', 0) or 0)
            if new_dist > dist[neighbor]:
                dist[neighbor] = new_dist
                parent[neighbor] = tid
    
    # æ‰¾åˆ°ç»ˆç‚¹ï¼ˆæœ€å¤§è·ç¦»çš„èŠ‚ç‚¹ï¼‰
    end_node = max(dist.keys(), key=lambda x: dist[x])
    
    # å›æº¯è·¯å¾„
    path = []
    node = end_node
    while node:
        path.append(node)
        node = parent[node]
    path.reverse()
    
    return path, dist[end_node]


def suggest_agents(analysis: dict) -> dict:
    """
    æ ¹æ®åˆ†æç»“æœå»ºè®® agent æ•°é‡
    """
    max_p = analysis['max_parallelism']
    max_count = analysis['max_parallelism_count']
    avg_p = analysis['avg_parallelism']
    weighted_avg = analysis['weighted_avg_parallelism']
    total_levels = analysis['total_levels']
    
    # å»ºè®®ç­–ç•¥
    suggestions = {
        'minimum': max(1, int(avg_p)),
        'recommended': max(1, round(weighted_avg)),
        'maximum': max_p,
    }
    
    # ç†ç”±
    reasons = []
    
    if max_count <= total_levels * 0.2:  # æœ€å¤§å¹¶è¡Œåº¦åªå‡ºç°åœ¨ 20% çš„å±‚çº§
        reasons.append(f"æœ€å¤§å¹¶è¡Œåº¦ {max_p} ä»…åœ¨ {max_count}/{total_levels} å±‚å‡ºç°")
        reasons.append(f"å»ºè®®ä½¿ç”¨ {suggestions['recommended']} ä¸ª agentï¼ˆåŠ æƒå¹³å‡ï¼‰")
    else:
        reasons.append(f"æœ€å¤§å¹¶è¡Œåº¦ {max_p} åœ¨ {max_count}/{total_levels} å±‚å‡ºç°")
        reasons.append(f"å¯è€ƒè™‘ä½¿ç”¨ {max_p} ä¸ª agent ä»¥æœ€å¤§åŒ–å¹¶è¡Œ")
    
    # æ—¶é—´ä¼°ç®—
    total_hours = analysis['total_hours']
    serial_time = total_hours
    parallel_time_max = total_hours / max_p if max_p > 0 else total_hours
    parallel_time_rec = total_hours / suggestions['recommended'] if suggestions['recommended'] > 0 else total_hours
    
    suggestions['time_estimate'] = {
        'serial': serial_time,
        'parallel_max': round(parallel_time_max, 1),
        'parallel_recommended': round(parallel_time_rec, 1),
    }
    
    suggestions['reasons'] = reasons
    
    return suggestions


# =============================================================================
# D2 DAG ç”Ÿæˆ
# =============================================================================

def generate_d2(tasks: List[dict], config: dict, analysis: dict) -> str:
    """ç”Ÿæˆ D2 æ ¼å¼çš„ DAG å›¾"""
    levels = compute_levels(tasks)
    _, _, details = build_graph(tasks)
    
    status_colors = config.get('çŠ¶æ€é¢œè‰²', {})
    
    lines = [
        "# ä»»åŠ¡ä¾èµ– DAG",
        "# è‡ªåŠ¨ç”Ÿæˆï¼Œè¯·å‹¿æ‰‹åŠ¨ç¼–è¾‘",
        "",
        "direction: down",
        "",
    ]
    
    # å®šä¹‰èŠ‚ç‚¹
    lines.append("# ä»»åŠ¡èŠ‚ç‚¹")
    for task in tasks:
        tid = task['ç¼–å·']
        name = task['åç§°']
        hours = task.get('å·¥æ—¶', '?')
        status = task.get('çŠ¶æ€', 'å¾…å¤„ç†')
        color = status_colors.get(status, '#9E9E9E')
        level = levels[tid]
        
        # èŠ‚ç‚¹å®šä¹‰
        label = f"{tid}\\n{name}\\n({hours}h)"
        lines.append(f'{tid}: "{label}" {{')
        lines.append(f'  style.fill: "{color}"')
        lines.append(f'  style.stroke: "{color}"')
        if status == 'å·²å®Œæˆ':
            lines.append('  style.opacity: 0.6')
        lines.append('}')
    
    lines.append("")
    lines.append("# ä¾èµ–å…³ç³»")
    
    # å®šä¹‰è¾¹
    for task in tasks:
        tid = task['ç¼–å·']
        for dep in task.get('ä¾èµ–', []):
            lines.append(f"{dep} -> {tid}")
    
    # æ·»åŠ å›¾ä¾‹
    lines.extend([
        "",
        "# å›¾ä¾‹",
        "legend: {",
        '  label: "å›¾ä¾‹"',
        "  near: bottom-center",
        "  å¾…å¤„ç†: {style.fill: \"#9E9E9E\"}",
        "  è¿›è¡Œä¸­: {style.fill: \"#2196F3\"}",
        "  å·²å®Œæˆ: {style.fill: \"#4CAF50\"}",
        "  å·²é˜»å¡: {style.fill: \"#F44336\"}",
        "}",
    ])
    
    return '\n'.join(lines)


# =============================================================================
# æŠ¥å‘Šç”Ÿæˆ
# =============================================================================

def print_analysis_report(tasks: List[dict], analysis: dict, critical_path: Tuple[List[str], int], suggestions: dict):
    """æ‰“å°åˆ†ææŠ¥å‘Š"""
    _, _, details = build_graph(tasks)
    
    print("\n" + "=" * 60)
    print("  ä»»åŠ¡ DAG åˆ†ææŠ¥å‘Š")
    print("=" * 60)
    
    # åŸºæœ¬ç»Ÿè®¡
    print(f"\nğŸ“Š åŸºæœ¬ç»Ÿè®¡")
    print(f"   æ€»ä»»åŠ¡æ•°:     {analysis['total_tasks']}")
    print(f"   æ€»å·¥æ—¶:       {analysis['total_hours']} å°æ—¶")
    print(f"   å±‚çº§æ•°:       {analysis['total_levels']}")
    
    # å¹¶è¡Œåº¦åˆ†æ
    print(f"\nğŸ“ˆ å¹¶è¡Œåº¦åˆ†æ")
    print(f"   æœ€å¤§å¹¶è¡Œåº¦:   {analysis['max_parallelism']} (å‡ºç° {analysis['max_parallelism_count']} æ¬¡)")
    print(f"   å¹³å‡å¹¶è¡Œåº¦:   {analysis['avg_parallelism']:.1f}")
    print(f"   åŠ æƒå¹³å‡:     {analysis['weighted_avg_parallelism']:.1f}")
    
    # æ¯å±‚è¯¦æƒ…
    print(f"\nğŸ“‹ å„å±‚çº§ä»»åŠ¡")
    for level, tids in sorted(analysis['levels'].items()):
        tasks_str = ', '.join(tids)
        hours = sum(details[t].get('å·¥æ—¶', 0) or 0 for t in tids)
        print(f"   ç¬¬ {level} å±‚: [{len(tids)} ä¸ªä»»åŠ¡, {hours}h] {tasks_str}")
    
    # å…³é”®è·¯å¾„
    path, path_hours = critical_path
    print(f"\nğŸ”´ å…³é”®è·¯å¾„ ({path_hours} å°æ—¶)")
    print(f"   {' â†’ '.join(path)}")
    
    # Agent å»ºè®®
    print(f"\nğŸ¤– Agent æ•°é‡å»ºè®®")
    print(f"   æœ€å°‘:    {suggestions['minimum']} ä¸ª")
    print(f"   æ¨è:    {suggestions['recommended']} ä¸ª â­")
    print(f"   æœ€å¤š:    {suggestions['maximum']} ä¸ª")
    
    for reason in suggestions['reasons']:
        print(f"   ğŸ’¡ {reason}")
    
    # æ—¶é—´ä¼°ç®—
    te = suggestions['time_estimate']
    print(f"\nâ±ï¸  æ—¶é—´ä¼°ç®—")
    print(f"   ä¸²è¡Œæ‰§è¡Œ:         {te['serial']} å°æ—¶")
    print(f"   {suggestions['recommended']} ä¸ª agent å¹¶è¡Œ:  ~{te['parallel_recommended']} å°æ—¶")
    print(f"   {suggestions['maximum']} ä¸ª agent å¹¶è¡Œ:  ~{te['parallel_max']} å°æ—¶")
    
    print("\n" + "=" * 60 + "\n")


# =============================================================================
# ä¸»å‡½æ•°
# =============================================================================

def main():
    import argparse
    
    parser = argparse.ArgumentParser(description='ä»»åŠ¡ DAG åˆ†æå·¥å…·')
    parser.add_argument('--tasks', '-t', default='.ai-context/tasks/tasks.yaml',
                        help='ä»»åŠ¡é…ç½®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--output', '-o', default='docs/diagrams/task-dag.d2',
                        help='D2 è¾“å‡ºæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--analyze-only', '-a', action='store_true',
                        help='ä»…åˆ†æï¼Œä¸ç”Ÿæˆ D2 æ–‡ä»¶')
    parser.add_argument('--generate-only', '-g', action='store_true',
                        help='ä»…ç”Ÿæˆ D2 æ–‡ä»¶ï¼Œä¸æ‰“å°åˆ†æ')
    
    args = parser.parse_args()
    
    # åŠ è½½æ•°æ®
    try:
        data = load_tasks(args.tasks)
    except FileNotFoundError:
        print(f"é”™è¯¯: æ‰¾ä¸åˆ°æ–‡ä»¶ {args.tasks}")
        sys.exit(1)
    except yaml.YAMLError as e:
        print(f"é”™è¯¯: YAML è§£æå¤±è´¥ - {e}")
        sys.exit(1)
    
    tasks = data.get('ä»»åŠ¡', [])
    config = data.get('DAGé…ç½®', {})
    
    if not tasks:
        print("è­¦å‘Š: æ²¡æœ‰æ‰¾åˆ°ä»»åŠ¡å®šä¹‰")
        sys.exit(0)
    
    # åˆ†æ
    analysis = analyze_parallelism(tasks)
    critical_path = find_critical_path(tasks)
    suggestions = suggest_agents(analysis)
    
    # æ‰“å°æŠ¥å‘Š
    if not args.generate_only:
        print_analysis_report(tasks, analysis, critical_path, suggestions)
    
    # ç”Ÿæˆ D2
    if not args.analyze_only:
        d2_content = generate_d2(tasks, config, analysis)
        
        output_path = Path(args.output)
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(d2_content)
        
        print(f"âœ… D2 æ–‡ä»¶å·²ç”Ÿæˆ: {output_path}")
        print(f"   è¿è¡Œ 'd2 {output_path}' ç”Ÿæˆ SVG å›¾ç‰‡")


if __name__ == '__main__':
    main()
