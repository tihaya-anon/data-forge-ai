# DataForge AI - Project Context

> This file provides context for AI assistants working with this codebase.

## Project Overview

**DataForge AI** is a portfolio/demo project showcasing a modern big data + AI platform that combines:
1. **LLM Training Data Engineering** - Large-scale data processing pipeline for LLM pre-training
2. **RAG Knowledge Base** - Enterprise intelligent Q&A system with hybrid retrieval

This is a **demonstration project** for job-seeking purposes, not a production system.

## Tech Stack

| Layer | Technologies |
|-------|-------------|
| Message Queue | Apache Kafka |
| Stream Processing | Apache Flink |
| Batch Processing | Apache Spark |
| Data Lake | Apache Paimon + MinIO |
| Vector Database | Milvus |
| Full-text Search | Elasticsearch |
| Cache | Redis |
| OLAP | Apache Doris |
| Orchestration | Apache Airflow |
| Monitoring | Prometheus + Grafana |

## Project Structure

```
.
├── Makefile                    # Main entry, includes makefiles/*.mk
├── makefiles/
│   ├── diagrams.mk             # D2 diagram generation
│   ├── docker.mk               # Docker Compose operations
│   └── dev.mk                  # Development utilities
├── docker/
│   ├── compose.base.yml        # Network and volume definitions
│   ├── compose.storage.yml     # Kafka, Milvus, Redis, ES, MinIO
│   ├── compose.compute.yml     # Spark, Flink
│   ├── compose.orchestration.yml # Airflow
│   ├── compose.analytics.yml   # Doris
│   ├── compose.monitoring.yml  # Prometheus, Grafana
│   └── monitoring/             # Prometheus/Grafana configs
├── docs/
│   ├── diagrams/*.d2           # D2 diagram source files
│   ├── images/                 # Generated SVGs (gitignored, CI builds)
│   ├── ARCHITECTURE.md         # Detailed technical architecture
│   └── RESUME_DESCRIPTION.md   # Resume templates & interview prep
├── .github/workflows/
│   └── generate-diagrams.yml   # Auto-generate diagrams on push
└── README.md                   # Project documentation
```

## Key Design Decisions

1. **Modular Makefile**: Split into `makefiles/*.mk` for maintainability
2. **Modular Docker Compose**: Split by service group for selective startup
3. **Diagrams as Code**: D2 files in `docs/diagrams/`, SVGs generated by CI
4. **SVGs not committed**: Generated images are in `.gitignore`, built by GitHub Actions

## Common Commands

```bash
# Show all commands
make help

# Start specific service groups
make docker-storage      # Kafka, Milvus, Redis, ES, MinIO
make docker-compute      # Spark, Flink
make docker-monitoring   # Prometheus, Grafana

# Start everything
make docker-up

# Generate diagrams locally
make diagrams

# Show service URLs
make urls
```

## Code Conventions

### Makefile
- Use `printf` (not `echo`) for colored output
- Every target with `## comment` appears in `make help`
- Colors: `$(GREEN)`, `$(YELLOW)`, `$(CYAN)`, `$(RED)`, `$(NC)`

### Docker Compose
- Each file is self-contained (no YAML anchor cross-references)
- Network name: `dataforge`
- Container naming: `dataforge-<service>`
- All services include healthchecks

### D2 Diagrams
- Theme: 200, Layout: elk, Pad: 20
- No external icon URLs (causes 403 errors)
- No `near: right` (use `near: top-center`, `near: bottom-center`)

## Architecture Highlights

### LLM Training Data Pipeline
1. Data Cleaning → Deduplication (MinHash) → Quality Filtering → PII Removal → Data Mixing
2. Key metrics: 50TB+/day, 10B docs deduplicated in 4 hours

### RAG Knowledge Base
1. Dual-path processing: Flink (real-time) + Spark (batch)
2. Hybrid retrieval: Vector (Milvus) + BM25 (ES) + RRF fusion + Reranking
3. Key metrics: Sync <5s, Vector P99 <50ms, E2E <500ms

## When Modifying This Project

1. **Adding new Docker services**: Create or modify `docker/compose.*.yml`
2. **Adding new diagrams**: Create `.d2` file in `docs/diagrams/`, run `make diagrams`
3. **Adding new Make targets**: Add to appropriate `makefiles/*.mk` with `## comment`
4. **Changing architecture**: Update both diagram and `docs/ARCHITECTURE.md`
