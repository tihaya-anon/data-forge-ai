# 📝 简历项目描述模板

> 以下是针对不同场景优化的简历描述，可根据目标岗位选择使用

---

## 🎯 完整版描述（适合详细项目介绍）

### 项目名称
**DataForge AI - 大数据驱动的 LLM 训练与智能应用平台**

### 项目描述
基于流批一体架构构建的企业级 AI 数据基础设施，涵盖 LLM 训练数据工程和 RAG 智能知识库两大核心模块。平台支持 PB 级数据处理能力，日均处理训练数据 50TB+，RAG 知识库支撑 10万+ 日均查询请求。

### 核心职责

**一、LLM 训练数据工程**
- 设计并实现基于 Spark 的分布式数据清洗管道，包含编码转换、HTML 清理、语言检测等 10+ 处理算子，日处理数据量 50TB+
- 实现 MinHash + SimHash 混合去重方案，支持 10 亿级文档去重，处理耗时 < 4 小时，去重精度 98%+
- 基于 KenLM 困惑度模型和 fastText 分类器构建数据质量过滤系统，过滤低质量数据约 30%
- 实现 PII 敏感信息检测与脱敏模块，支持邮箱、手机、身份证等 10+ 类型实体识别
- 设计 Self-Instruct 指令数据合成 Pipeline，自动生成 100万+ 高质量指令微调数据
- 基于 Paimon/Iceberg 实现训练数据版本管理，支持任意版本数据回溯和实验复现

**二、RAG 智能知识库**
- 基于 Flink CDC 实现实时数据同步管道，支持 MySQL/PostgreSQL/MongoDB 等多数据源，文档变更秒级感知
- 设计智能文档分块策略（语义分块 + 滑动窗口），优化后检索召回率提升 15%
- 构建 Milvus 向量索引方案（HNSW 算法），支持 1 亿+ 向量毫秒级检索
- 实现混合检索策略（向量检索 + BM25 + RRF 融合 + BGE-Reranker），答案准确率达 90%+
- 设计 Query 改写模块（HyDE + Query Expansion），复杂问题理解能力提升 25%
- 使用 Airflow 编排完整数据处理 Pipeline，实现自动化运维和异常告警

### 技术栈
`Spark` `Flink` `Kafka` `Paimon` `Iceberg` `Milvus` `Airflow` `Doris` `LangChain` `Python` `Java`

### 项目成果
- 训练数据处理效率提升 3 倍，单日处理能力从 15TB 提升至 50TB+
- 知识库检索准确率从 70% 提升至 90%+
- 数据更新延迟从小时级降低至秒级
- 平台支撑公司 3 个 LLM 训练项目和 5 个业务知识库

---

## 📋 精简版描述（适合简历一页纸）

### 项目名称
**大数据 AI 平台 - LLM 训练数据 + RAG 知识库**

### 项目描述
基于 Flink + Spark + Paimon 构建的流批一体 AI 数据平台，涵盖训练数据处理和 RAG 知识库。

### 核心工作
- 基于 Spark 实现 PB 级训练数据处理管道（清洗/去重/质量过滤），日处理 50TB+
- 实现 MinHash 文档去重，10 亿级文档 4 小时完成，精度 98%+
- 基于 Flink CDC 构建实时知识库同步，文档变更秒级更新
- 设计混合检索 + Rerank 策略，RAG 准确率 90%+，检索延迟 P99<50ms
- 基于 Paimon 实现数据版本管理，支持训练数据溯源和实验复现

### 技术栈
`Spark` `Flink` `Kafka` `Paimon` `Milvus` `Airflow` `LangChain`

---

## 🔥 亮点提炼版（适合 STAR 法则面试）

### Situation（背景）
公司需要构建自研 LLM，面临两大挑战：
1. 缺乏高质量训练数据处理能力，原始数据噪声大、重复率高
2. 业务知识库更新延迟高，员工无法获取最新信息

### Task（任务）
作为数据平台核心开发，负责：
1. 设计 LLM 训练数据处理 Pipeline
2. 构建实时更新的 RAG 智能知识库

### Action（行动）

**训练数据工程：**
```
问题：10 亿级文档如何高效去重？
方案：MinHash (128 permutations) + LSH + Spark 分布式
优化：
  - 数据分桶减少 shuffle
  - Broadcast 小表优化 join
  - 自适应 threshold 调参
结果：4 小时完成，精度 98%+
```

**RAG 知识库：**
```
问题：如何提高检索准确率？
方案：混合检索 + Rerank
  - 向量检索 (Milvus HNSW)
  - 关键词检索 (BM25)
  - RRF 融合排序
  - BGE-Reranker 精排
结果：准确率从 70% 提升至 90%+
```

### Result（成果）
- 训练数据质量评分提升 40%（人工评测）
- 知识库更新延迟：小时级 → 秒级
- 支撑 3 个 LLM 项目成功上线

---

## 💡 不同岗位侧重点

### 数据工程师岗位
重点突出：
- Spark/Flink 大规模数据处理
- 数据质量、去重、清洗
- 数据湖架构（Paimon/Iceberg）
- Pipeline 设计和优化

### AI 工程师岗位
重点突出：
- RAG 检索策略优化
- Embedding 模型选型和优化
- LLM 应用开发（LangChain）
- 模型效果评估

### ML 平台工程师岗位
重点突出：
- 端到端 ML Pipeline
- 数据版本管理
- 特征工程
- MLOps 实践

### 后端开发岗位
重点突出：
- 高并发服务设计
- 分布式系统
- API 设计
- 系统性能优化

---

## 🎤 面试常见问题准备

### Q1: 为什么选择 MinHash 而不是 SimHash 做去重？
```
A: 两者各有适用场景：
- MinHash：适合 Jaccard 相似度，对文档级别的相似度检测更准确
- SimHash：适合海明距离，对短文本和局部修改更敏感

我们的场景是长文档去重，文档结构相对完整，MinHash 效果更好。
同时我们也用 SimHash 做段落级别的去重，两者结合使用。
```

### Q2: RAG 检索准确率是怎么评估的？
```
A: 我们建立了多层评估体系：
1. 自动评估：
   - 召回率 (Recall@K)
   - MRR (Mean Reciprocal Rank)
   - NDCG (Normalized DCG)

2. 人工评估：
   - 构建 500 条标注测试集
   - 答案相关性打分 (1-5)
   - 引用准确性检查

3. 在线评估：
   - 用户反馈（点赞/点踩）
   - 答案采纳率
```

### Q3: 如何保证实时和离线数据一致性？
```
A: 采用 Lambda 架构 + 数据校验：
1. 实时层：Flink CDC 秒级同步增量数据
2. 批处理层：Spark 每日全量校验
3. 一致性保障：
   - 数据 Checksum 校验
   - 版本号比对
   - 自动 diff 告警
```

### Q4: 遇到过什么技术难点？怎么解决的？
```
A: 最大挑战是 10 亿级文档去重的性能问题

初始方案：
- 直接两两比对，时间复杂度 O(n²)
- 预估耗时：几周

优化方案：
1. MinHash 签名压缩（128 permutations）
2. LSH 分桶，只比较同桶文档
3. Spark 优化：
   - 数据倾斜处理（盐值 + 二次聚合）
   - Broadcast 优化小表 join
   - 动态资源分配

最终结果：4 小时完成，性能提升 100 倍+
```

---

## 📊 量化指标参考

| 指标类型 | 示例指标 | 可引用数据 |
|----------|----------|------------|
| **规模** | 数据处理量 | 日处理 50TB+、10 亿级文档 |
| **性能** | 处理速度 | 10 亿文档去重 4 小时 |
| **效果** | 准确率 | 检索准确率 90%+、去重精度 98% |
| **延迟** | 响应时间 | P99 < 50ms、秒级同步 |
| **提升** | 优化效果 | 效率提升 3 倍、准确率提升 20% |
| **支撑** | 业务价值 | 支撑 3 个 LLM 项目、10 万日均查询 |

---

*以上数据仅供参考，请根据实际项目情况调整*
